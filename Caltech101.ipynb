{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMrjvoOaDddweEdpB9iuyBE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enVives/Caltech101/blob/main/Caltech101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TRqBiAE19FY4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb81a92d-38f1-4d9a-dd63-e89a99b5fd4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.cuda.Stream device=cuda:0 cuda_stream=0x0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from itertools import filterfalse\n",
        "import torch,torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import time\n",
        "import os\n",
        "\n",
        "from torchvision import transforms,models\n",
        "from torch import nn\n",
        "from IPython.display import clear_output,display\n",
        "from torch.utils.data import DataLoader, random_split,Subset,Dataset\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from glob import glob\n",
        "\n",
        "ROOT = './sample_data/'\n",
        "CLASS_A = 'cougar_body'\n",
        "CLASS_B = 'windsor_chair'\n",
        "\n",
        "DOWNLOAD = False\n",
        "#!rm -rf /content/sample_data/*\n",
        "torch.cuda.default_stream(torch.device('cuda'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_mean_std(dataset):\n",
        "  dataloader = DataLoader(dataset,batch_size = 1,shuffle=FALSE)\n",
        "  mean = torch.zeros(3)\n",
        "  std = torch.zeros(3)\n",
        "  samples = 0\n",
        "\n",
        "  for image,_ in dataloader:\n",
        "    mean += image.mean(dim=[0, 2, 3])  # Mean for each channel [batchsize,channels,height,width]\n",
        "    std += image.std(dim=[0, 2, 3])    # Std for each channel\n",
        "    samples += 1\n",
        "\n",
        "  mean /= samples\n",
        "  std /= samples\n",
        "\n",
        "  print(mean)\n",
        "  print(std)"
      ],
      "metadata": {
        "id": "4JYb0AOJbCdC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Formes(Dataset):\n",
        "    def __init__(self, paths, labels= None, transforms = None):\n",
        "        self.images = paths\n",
        "        self.labels = labels\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getdist__(self):\n",
        "      return pd.Series(self.labels).value_counts()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      path = self.images[index]\n",
        "      label = self.labels[index]\n",
        "\n",
        "      image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "      image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "      image = self.transforms(image)\n",
        "\n",
        "      return image, label"
      ],
      "metadata": {
        "id": "8imK0xLhEnm1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_labels(sett):\n",
        "  labels = np.array([])\n",
        "  frequency = np.zeros(101)\n",
        "  for _,label in sett:\n",
        "    labels = np.append(labels,label)\n",
        "    frequency[label] += 1\n",
        "  return labels.astype(int),frequency"
      ],
      "metadata": {
        "id": "ifL4lRvNSHlm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from pickle import FALSE\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "TRAINING = 0.80\n",
        "VAL = 0.10\n",
        "TESTING = 0.10\n",
        "\n",
        "#[0.5459, 0.5288, 0.5022]\n",
        "#[0.2424, 0.2393, 0.2409]\n",
        "mean = torch.tensor([0.5459, 0.5288, 0.5022])\n",
        "std = torch.tensor([0.2424, 0.2393, 0.2409])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Lambda(lambda img: img.convert(\"RGB\") if img.mode != \"RGB\" else img),  # Ensure all images are RGB\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "dataset = torchvision.datasets.Caltech101(root= ROOT,download=DOWNLOAD,transform=transform)\n",
        "img_files = sorted(glob('/content/sample_data/caltech101/101_ObjectCategories/*/*'))\n",
        "\n",
        "labels = []\n",
        "for img_path in img_files:\n",
        "  label = img_path.split(os.path.sep)[-2]\n",
        "  labels.append(label)\n",
        "\n",
        "lb = LabelEncoder()\n",
        "labels = lb.fit_transform(labels)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(img_files, labels, test_size=TESTING, random_state=42, stratify=labels)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=VAL/(TRAINING+VAL), random_state=42, stratify=y_train)\n",
        "\n",
        "training = Formes(X_train,y_train,transform)\n",
        "testing = Formes(X_test,y_test,transform)\n",
        "validation = Formes(X_val,y_val,transform)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#training,validation,testing = random_split(dataset,[train_size,validation_size,len(dataset)-train_size-validation_size])"
      ],
      "metadata": {
        "id": "5e-PEAT6NDpO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"LONGITUD SET DE TRAINING: {training.__len__()}\")\n",
        "print(f\"LONGITUD SET DE VALIDATION: {validation.__len__()}\")\n",
        "print(f\"LONGITUD SET DE TESTING: {testing.__len__()}\")"
      ],
      "metadata": {
        "id": "npbH2OEvRSVh",
        "outputId": "bb58acef-549b-49e2-9cfc-4aa7a2723bb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LONGITUD SET DE TRAINING: 7315\n",
            "LONGITUD SET DE VALIDATION: 915\n",
            "LONGITUD SET DE TESTING: 915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ara ja sabem que hem de predir si una imatge pertany a les classes 25 o 99"
      ],
      "metadata": {
        "id": "riWfhpfjmgeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pick_algorithm(number):\n",
        "  if number == 0:\n",
        "    alexnetmulticlass = models.alexnet(weights=None)\n",
        "\n",
        "    alexnetmulticlass.classifier = nn.Sequential(\n",
        "    torch.nn.Linear(9216, 1024),\n",
        "    nn.ReLU(),\n",
        "    torch.nn.Linear(1024, 1024),\n",
        "    nn.ReLU(),\n",
        "    torch.nn.Linear(1024, 512),\n",
        "    nn.ReLU(),\n",
        "    torch.nn.Linear(512, 102),  # Ja que tenim 101 classes.\n",
        "    )\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    #weight=class_weights.to(device)\n",
        "    return alexnetmulticlass,loss_fn"
      ],
      "metadata": {
        "id": "cCt3W6wGUr_t"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def veure_imatges(train_data,std,mean):\n",
        "  for i in range(len(train_data)):\n",
        "    imatge,label = train_data[i]\n",
        "\n",
        "    print(imatge.ndimension())\n",
        "    print(imatge.shape)\n",
        "\n",
        "    imatge = imatge * (std[:, None, None]*255) + (mean[:, None, None]*255)\n",
        "    # Convert the tensor back to a NumPy array\n",
        "    img_numpy = imatge.permute(1, 2, 0).numpy()  # Change from (C, H, W) to (H, W, C)\n",
        "    cv2_imshow(img_numpy)\n",
        "    time.sleep(5)\n",
        "    clear_output(wait=True)"
      ],
      "metadata": {
        "id": "q6rpD5v8EW8G"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 95\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(training, batch_size=BATCH_SIZE, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation, batch_size=BATCH_SIZE, shuffle=True)\n",
        "testing_loader = torch.utils.data.DataLoader(testing, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "model,loss_fn = pick_algorithm(0)\n",
        "model.to(device)\n",
        "\n",
        "learning_rate = 1e-3\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "#veure_imatges(training,std,mean)"
      ],
      "metadata": {
        "id": "rjilieRW5Rzj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "47a914fe-6f4d-41ac-915b-bda6565ea5f2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-90bb0d0550e4>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpick_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1324\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m                     )\n\u001b[0;32m-> 1326\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1327\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img, target = next(iter(train_loader))\n",
        "print(img.shape)"
      ],
      "metadata": {
        "id": "wqzBODaIK61P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
        "from tqdm.auto import tqdm\n",
        "import pylab as pl\n",
        "\n",
        "t_loss = np.zeros(EPOCHS)\n",
        "v_loss = np.zeros(EPOCHS)\n",
        "acc_t = np.zeros(EPOCHS) #accuracy\n",
        "acc_v = np.zeros(EPOCHS)\n",
        "f1_t = np.zeros(EPOCHS) #f1\n",
        "f1_v = np.zeros(EPOCHS)\n",
        "recall_t = np.zeros(EPOCHS) #recall\n",
        "recall_v = np.zeros(EPOCHS)\n",
        "precision_t = np.zeros(EPOCHS)\n",
        "precision_v = np.zeros(EPOCHS) #precisió\n",
        "\n",
        "\n",
        "pbar = tqdm(range(1, EPOCHS + 1))  # tdqm permet tenir text dinàmic\n",
        "\n",
        "classes = []\n",
        "\n",
        "def extreu_classes(target):\n",
        "    for i in target:\n",
        "      if i not in classes:\n",
        "        classes.append(i)\n",
        "\n",
        "for epoch in pbar:\n",
        "\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    train_f1 = 0\n",
        "    train_recall = 0\n",
        "    train_precision = 0\n",
        "    val_acc = 0\n",
        "    val_recall = 0\n",
        "    val_f1 = 0\n",
        "    val_loss = 0\n",
        "    val_precision = 0\n",
        "\n",
        "    batch_num = 1\n",
        "\n",
        "    for batch_num, (input_img, target) in tqdm(enumerate(train_loader), desc=f\"Batches (Època {epoch})\"):\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        #extreu_classes(target.to(device))\n",
        "\n",
        "        output = model(input_img.to(device))\n",
        "\n",
        "        # print(target.shape)\n",
        "        # print(output.shape)\n",
        "\n",
        "        target = target.to(device)\n",
        "        loss = loss_fn(output, target)\n",
        "\n",
        "\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            optimizer.step()\n",
        "\n",
        "        #print(f\"Pèrdua entrenament batch: {batch_num} epoch: {epoch+1}  train_loss: {loss.item()}\")\n",
        "        model.eval()\n",
        "\n",
        "        y_class_predict = torch.argmax(output, dim=1)\n",
        "        y_class_predict = (y_class_predict.cpu().detach().numpy())\n",
        "        target = target.cpu().detach().numpy()\n",
        "\n",
        "\n",
        "        train_acc += accuracy_score(target,y_class_predict)\n",
        "        train_f1 += f1_score(target,y_class_predict,zero_division=1,average='macro')\n",
        "        train_recall += recall_score(target,y_class_predict,zero_division=1,average='macro')\n",
        "        train_precision += precision_score(target,y_class_predict,zero_division=1,average='macro')\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    #with torch.no_grad():\n",
        "        for batch_num, (input_img, target) in enumerate(validation_loader):\n",
        "\n",
        "\n",
        "            output = model(input_img.to(device))\n",
        "            target = target.to(device)\n",
        "            loss = loss_fn(output, target)\n",
        "\n",
        "            y_class_predict = torch.argmax(output, dim=1)\n",
        "            y_class_predict = (y_class_predict.cpu().detach().numpy())\n",
        "\n",
        "            target = target.cpu().detach().numpy()\n",
        "\n",
        "            val_acc  += accuracy_score(target,y_class_predict)\n",
        "            val_f1 += f1_score(target,y_class_predict,zero_division=1,average='macro')\n",
        "            val_recall += recall_score(target,y_class_predict,zero_division=1,average='macro')\n",
        "            val_precision += precision_score(target,y_class_predict,zero_division=1,average='macro')\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            #print(f\"Pèrdua entrenament batch validacio: {batch_num} epoch: {epoch+1}  val_loss: {val_loss.item()}\")\n",
        "\n",
        "            # RESULTATS\n",
        "    train_loss /= len(train_loader)\n",
        "    t_loss[epoch - 1] = train_loss\n",
        "\n",
        "    train_acc /= len(train_loader)\n",
        "    acc_t[epoch - 1] = train_acc\n",
        "\n",
        "    train_f1 /= len(train_loader)\n",
        "    f1_t[epoch - 1] = train_f1\n",
        "\n",
        "    train_recall /= len(train_loader)\n",
        "    recall_t[epoch - 1] = train_recall\n",
        "\n",
        "    train_precision /= len(train_loader)\n",
        "    precision_t[epoch-1] = train_precision\n",
        "\n",
        "    print(f\"Pèrdua entrenament epoch: {epoch}  train_loss: {train_loss}\")\n",
        "    print(f\"Accuracy train epoch: {epoch}  train_acc: {train_acc}\")\n",
        "    print(f\"F1 train epoch: {epoch}  train_f1: {train_f1}\")\n",
        "    print(f\"Recall train epoch: {epoch}  train_recall: {train_recall}\")\n",
        "    print(f\"Precision train epoch: {epoch}  train_recall: {train_precision}\")\n",
        "\n",
        "    val_loss /= len(validation_loader)\n",
        "    v_loss[epoch - 1] = val_loss\n",
        "\n",
        "    val_acc /= len(validation_loader)\n",
        "    acc_v[epoch - 1] = val_acc\n",
        "\n",
        "    val_f1 /= len(validation_loader)\n",
        "    f1_v[epoch - 1] = val_f1\n",
        "\n",
        "    val_recall /= len(validation_loader)\n",
        "    recall_v[epoch - 1] = val_recall\n",
        "\n",
        "    val_precision /= len(validation_loader)\n",
        "    precision_v[epoch-1] = val_precision\n",
        "\n",
        "    print()\n",
        "    print()\n",
        "    print(f\"Pèrdua validació epoch: {epoch}  val_loss: {val_loss}\")\n",
        "    print(f\"Accuracy val epoch: {epoch}  val_acc: {val_acc}\")\n",
        "    print(f\"F1 val epoch: {epoch}  val_f1: {val_f1}\")\n",
        "    print(f\"Recall val epoch: {epoch}  val_reall: {val_recall}\")\n",
        "    print(f\"Precision val epoch: {epoch}  val_reall: {val_precision}\")"
      ],
      "metadata": {
        "id": "liyfoGfI6CzM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}